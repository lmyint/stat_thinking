---
title: "Review of statistical concepts"
output:
  ioslides_presentation:
    widescreen: true
    css: ../styles/styles.css
---

## Goal: learning about the world

Our understanding about the world is all about understanding inputs and outputs.

What are the **effects** of inputs on outputs?

Once a clear question is put forth, a statistical approach to learning about effects is to **estimate** them.

<div class="notes">
An imprecise question: what is the relationship between smoking and lung cancer?
Both smoking and lung cancer need to be quantifiable
To understand statistical estimation, we have to review the concept of random variables
</div>

## Variables

What is the difference between the variable $X$ in these two situations?

$$ X = \hbox{age of next person who walks through the door} $$

$$ \hbox{Age when finished grad school} = \hbox{age now} + X $$

## Random variables

**Random variables** are variables that can take a range of possible values because of some random process.

Contrast with an algebraic variable whose value is fixed given an associated equation

## Random variables

The defining property of a random variable is its **distribution function**. This function tells us how likely different sets of values are.

Discrete random variables can take countably many values, and their distribution function is called a **probability mass function** written as:

$$ p(x) = P(X = x) $$

Continuous random variables take uncountably many values, and their distribution function is called a **probability density function** written as:

$$ f(x) \qquad \mathrm{where} \qquad P(X \in A) = \int_A f(x)\,dx $$

## Random variables

Random variables are denoted by capital letters, and their **realizations** (observed values) are denoted by lowercase letters.

When we collect data, we represent our outcomes as a set of random variables: $X_1,\ldots,X_n$.

Important to keep in mind: what parts of our data do we represent as random variables and what parts do we represent as fixed?

## Mean and variance

Using the distribution function, we can compute important properties such as the mean:

$$
\begin{align}
E[X] &= \sum_{x \in S} x p(x) \qquad\qquad \mathrm{discrete} \\
E[X] &= \int_{S} x f(x)\,dx \qquad \mathrm{continuous}
\end{align}
$$

and variance:

$$
\begin{align}
\mathrm{Var}(X) &= \sum_{x \in S} (x-E[X])^2 p(x) \qquad\qquad \mathrm{discrete} \\
\mathrm{Var}(X) &= \int_{S} (x-E[X])^2 p(x)\,dx \qquad \mathrm{continuous}
\end{align}
$$

where $S$ is the set of values that the random variable $X$ can take.

## Binomial distribution

$$ X \sim \mathrm{Binomial}(n,p) $$
$$ p(x) = P(X = x) = \binom{n}{x}p^x (1-p)^{n-x} $$
$$ E[X] = np $$
$$ \mathrm{Var}(X) = np(1-p) $$

<div class="notes">
Ask if p(1-p) looks familiar
</div>

## Normal distribution

$$ X \sim \mathrm{Normal}(\mu, \sigma) $$
$$ f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left( -\frac{(x-\mu)^2}{2\sigma^2} \right) $$
$$ E[X] = \mu $$
$$ \mathrm{Var}(X) = \sigma^2 $$

## Important distributions

Discrete

- Bernoulli and binomial: binary outcomes
- Multinomial: categorical outcomes
- Poisson: count data
- Negative binomial: count data with higher variability

Continuous

- Normal (Gaussian) and its relatives: $t$, $F$, $\chi^2$
- Exponential: rare outcomes

<div class="notes">
These distributions are well known and useful because they serve as useful **models** for many situations in real life.
</div>

## Modeling real data with familiar distributions

Distributions of real quantities can be arbitrarily messy. We use known distributions as building blocks to model real world data.

```{r echo=FALSE}
set.seed(1)
x <- c(rnorm(100), rbeta(400, 0.5, 0.5), runif(300, -3, 2), rnorm(200, -1.5))
plot(density(x), xlab = "x", main = "Probability distribution function")
```

## Known distributions: what's the use?

Why do we care if a quantity follows, say, a normal distribution?

The normal distribution has two **parameters** ($\mu$ and $\sigma$) that completely determine the density function.

- If we can figure out what the values of $\mu$ and $\sigma$ are, we know a lot!

## Known distributions: what's the use?

Two caveats with using known distributions

- When we have data, we almost never know that it comes from a certain distribution
    - Can use exploratory plots and goodness of fit tests to guess
- Even if we have a guess, it's almost certainly not exactly true
    - "All models are wrong, but some are useful" - George Box

## Likelihood

When we are able to write that our data observations come from a combination of known distributions, we are able to write the **likelihood function** for our data:

$$ L(x_1,\ldots,x_n; \theta) = \prod_{i=1}^n f(x_i; \theta) $$

For mathematical reasons, we often work with the **log-likelihood function**:

$$ l(x_1,\ldots,x_n; \theta) = \sum_{i=1}^n \log f(x_i; \theta) $$

The "; $\theta$" is notation to indicate that the density function, and thus the likelihood, depend on a parameter $\theta$.

## Likelihood

In statistics, we often refer to "the likelihood under a model." What does that mean?

- [Blog post](https://lesliemyint.wordpress.com/2016/02/09/what-is-likelihood/)
- To write the likelihood function on the last slide, we needed the density function $f$
- If we know $f$ then we're assuming a model for our data

## Uses of likelihood

**Maximum likelihood estimation**:

$$ \frac{d}{d\theta} l(x_1,\ldots,x_n; \theta) = 0 $$

Solve for $\theta$ to get an **estimator** for $\theta$ that is a function of the data:

$$ \hat\theta = \mathrm{function}(x_1,\ldots,x_n) $$

## Uses of likelihood

**Likelihood ratios**: If you have two models in the same family (say two binomial models with different success probabilities $p_1$ and $p_2$), you can compare their appropriateness for the data using a likelihood ratio

$$ \frac{L(x_1,\ldots,x_n)}{} $$

## Estimators

- Functions of the observed data that estimate the parameter of interest
- Examples
    - Maximum likelihood estimators
    - Sample mean
$$ \bar{X} = \sum_{i=1}^n X_i $$
    - Sample variance
$$ s^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2 $$

## Properties of estimators

Estimators themselves are random variables and thus have a distribution. When we use estimators, we are typically interested in:

- Bias: $E[\hat\theta]-\theta$
- Mean squared error: $E[(\hat\theta-\theta)^2]$
- Variability: $\mathrm{Var}(\hat\theta)$ or $\mathrm{SD}(\hat\theta)$
    - $\mathrm{SD}(\hat\theta)$ is also called the standard error of $\hat\theta$
- Classification/prediction accuracy
    - Fraction of the time the correct class is predicted
    - Receiver operating characteristic (ROC) curves and area under the curve (AUC)

## Bias-variance tradeoff

The mean squared error of an estimator can be decomposed into a variance term and a bias term:

$$ \mathrm{MSE}(\hat\theta) = \mathrm{Var}(\hat\theta) + \mathrm{Bias}(\hat\theta)^2 $$

- [Proof](https://en.wikipedia.org/wiki/Mean_squared_error#Proof_of_variance_and_bias_relationship)
- Tells us that we can improve either variance or bias at the expense of the other
    - Most often we are willing to accept a little more bias for much less variance

## Distribution of estimators

The distribution of the random variable $\bar{X}$ is also called the **sampling distribution** of the sample mean. Interested in how this distribution changes as sample size increases:

```{r}
par(mfrow = c(1,3))
lambda <- 2
pop <- rexp(1e6, rate = lambda)
numSamples <- 5000
for (n in c(10,100,1000)) {
	sampMeans <- sapply(seq_len(5000), function(i) { mean(sample(pop, size = n)) })
	hist(sampMeans, xlab = "Sample mean", main = paste("Distribution of", numSamples, "sample means\nof size", n))
}
```

## Central limit theorem

We have data observations $X_1, X_2, \ldots$. Let $n$ denote the sample size, $\mu = E[X_i]$, $\sigma^2 = \mathrm{Var}(X_i)$. Then as $n \to \infty$, the distribution of 

$$ \sqrt n (\bar X - \mu) $$

approaches a $\mathrm{Normal}(0,\sigma^2)$ distribution.

This is the main theoretical result that allows us to construct **confidence intervals**.

## Confidence intervals

Recall: 95% confidence interval for an estimate

$$ \mathrm{estimate} \pm 2 \mathrm{SE}(\mathrm{estimate}) $$

More specifically this should be

$$ \mathrm{estimate} \pm z_{0.975} \mathrm{SE}(\mathrm{estimate}) $$

where $z_{0.975}$ is the value at which the area under the Normal(0,1) density up to that value is 0.975.

## Law of large numbers

The law of large numbers is the theoretical result underlying our greater trust in larger samples. It says that as the sample size $n \to \infty$, the sample mean approaches the true mean.

## Estimation framework: regression

Regression is a class of tools used to estimate effects of covariates on an outcome

What does it mean to "fit" a model? Obtain coefficients

## Causal diagrams and confounding

## Conditional probability
