<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Statistical Thinking for Informed Decision Making</title>
  <meta name="description" content="This is the class textbook for Statistical Thinking for Informed Decision Making.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Statistical Thinking for Informed Decision Making" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the class textbook for Statistical Thinking for Informed Decision Making." />
  <meta name="github-repo" content="lmyint/stat_thinking/textbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistical Thinking for Informed Decision Making" />
  
  <meta name="twitter:description" content="This is the class textbook for Statistical Thinking for Informed Decision Making." />
  

<meta name="author" content="Leslie Myint">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chap-hypo-test.html">
<link rel="next" href="chap-causal-background.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Thinking</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="chap-hypo-test.html"><a href="chap-hypo-test.html"><i class="fa fa-check"></i><b>1</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="1.1" data-path="chap-hypo-test.html"><a href="chap-hypo-test.html#aside-what-is-statistical-inference"><i class="fa fa-check"></i><b>1.1</b> Aside: what is statistical inference?</a></li>
<li class="chapter" data-level="1.2" data-path="chap-hypo-test.html"><a href="chap-hypo-test.html#conceptual-framework"><i class="fa fa-check"></i><b>1.2</b> Conceptual framework</a></li>
<li class="chapter" data-level="1.3" data-path="chap-hypo-test.html"><a href="chap-hypo-test.html#statistical-details"><i class="fa fa-check"></i><b>1.3</b> Statistical details</a><ul>
<li class="chapter" data-level="1.3.1" data-path="chap-hypo-test.html"><a href="chap-hypo-test.html#one-and-two-tailed-tests"><i class="fa fa-check"></i><b>1.3.1</b> One and two-tailed tests</a></li>
<li class="chapter" data-level="1.3.2" data-path="chap-hypo-test.html"><a href="chap-hypo-test.html#statistical-power"><i class="fa fa-check"></i><b>1.3.2</b> Statistical power</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="chap-hypo-test.html"><a href="chap-hypo-test.html#common-statistical-tests"><i class="fa fa-check"></i><b>1.4</b> Common statistical tests</a><ul>
<li class="chapter" data-level="1.4.1" data-path="chap-hypo-test.html"><a href="chap-hypo-test.html#tests-for-comparing-continuous-data"><i class="fa fa-check"></i><b>1.4.1</b> Tests for comparing continuous data</a></li>
<li class="chapter" data-level="1.4.2" data-path="chap-hypo-test.html"><a href="chap-hypo-test.html#tests-for-comparing-categorical-data"><i class="fa fa-check"></i><b>1.4.2</b> Tests for comparing categorical data</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="chap-hypo-test.html"><a href="chap-hypo-test.html#multiple-testing"><i class="fa fa-check"></i><b>1.5</b> Multiple testing</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chap-modeling.html"><a href="chap-modeling.html"><i class="fa fa-check"></i><b>2</b> Regression Modeling</a><ul>
<li class="chapter" data-level="2.1" data-path="chap-modeling.html"><a href="chap-modeling.html#regression-overview"><i class="fa fa-check"></i><b>2.1</b> Regression overview</a></li>
<li class="chapter" data-level="2.2" data-path="chap-modeling.html"><a href="chap-modeling.html#linear-regression"><i class="fa fa-check"></i><b>2.2</b> Linear regression</a><ul>
<li class="chapter" data-level="2.2.1" data-path="chap-modeling.html"><a href="chap-modeling.html#interpreting-coefficients"><i class="fa fa-check"></i><b>2.2.1</b> Interpreting coefficients</a></li>
<li class="chapter" data-level="2.2.2" data-path="chap-modeling.html"><a href="chap-modeling.html#interaction"><i class="fa fa-check"></i><b>2.2.2</b> Interaction</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="chap-modeling.html"><a href="chap-modeling.html#logistic-regression"><i class="fa fa-check"></i><b>2.3</b> Logistic regression</a></li>
<li class="chapter" data-level="2.4" data-path="chap-modeling.html"><a href="chap-modeling.html#generalized-linear-models"><i class="fa fa-check"></i><b>2.4</b> Generalized linear models</a></li>
<li class="chapter" data-level="2.5" data-path="chap-modeling.html"><a href="chap-modeling.html#model-selection"><i class="fa fa-check"></i><b>2.5</b> Model selection</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chap-causal-background.html"><a href="chap-causal-background.html"><i class="fa fa-check"></i><b>3</b> Causal Inference: Background</a><ul>
<li class="chapter" data-level="3.1" data-path="chap-causal-background.html"><a href="chap-causal-background.html#bradford-hill-criteria"><i class="fa fa-check"></i><b>3.1</b> Bradford Hill criteria</a></li>
<li class="chapter" data-level="3.2" data-path="chap-causal-background.html"><a href="chap-causal-background.html#exercise-comparing-two-statisticians"><i class="fa fa-check"></i><b>3.2</b> Exercise: comparing two statisticians</a></li>
<li class="chapter" data-level="3.3" data-path="chap-causal-background.html"><a href="chap-causal-background.html#rubin-causal-model"><i class="fa fa-check"></i><b>3.3</b> Rubin causal model</a><ul>
<li class="chapter" data-level="3.3.1" data-path="chap-causal-background.html"><a href="chap-causal-background.html#revisiting-lords-paradox"><i class="fa fa-check"></i><b>3.3.1</b> Revisiting Lord’s paradox</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="chap-causal-background.html"><a href="chap-causal-background.html#types-of-causal-effects"><i class="fa fa-check"></i><b>3.4</b> Types of causal effects</a></li>
<li class="chapter" data-level="3.5" data-path="chap-causal-background.html"><a href="chap-causal-background.html#how-do-we-learn-about-causal-effects"><i class="fa fa-check"></i><b>3.5</b> How do we learn about causal effects?</a><ul>
<li class="chapter" data-level="3.5.1" data-path="chap-causal-background.html"><a href="chap-causal-background.html#replication"><i class="fa fa-check"></i><b>3.5.1</b> Replication</a></li>
<li class="chapter" data-level="3.5.2" data-path="chap-causal-background.html"><a href="chap-causal-background.html#stable-unit-treatment-value-assumption-sutva"><i class="fa fa-check"></i><b>3.5.2</b> Stable Unit Treatment Value Assumption (SUTVA)</a></li>
<li class="chapter" data-level="3.5.3" data-path="chap-causal-background.html"><a href="chap-causal-background.html#assignment-mechanism"><i class="fa fa-check"></i><b>3.5.3</b> Assignment mechanism</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Thinking for Informed Decision Making</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chap_modeling" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Regression Modeling</h1>
<p>Models, generally speaking, are simplified descriptions of the world that distill the workings of a system into its essential parts. We construct models mainly for two purposes: to explain our observations and to predict what will happen in the future using data we have now. Much of public health research has the goal of understanding the relationship between outcomes and exposures or other characteristics. To this end, we will expand our toolbox to include a class of models, called <strong>generalized linear models</strong>, that can handle different types of data we see in public health research. Because common study designs in public health research violate the assumptions for this class of models, we will also look at other modeling strategies that can be used in such cases.</p>
<div id="regression-overview" class="section level2">
<h2><span class="header-section-number">2.1</span> Regression overview</h2>
<p>Regression is a class of techniques that is used to describe outcomes as a function of predictor variables, also called <strong>covariates</strong>. Because there are different types of outcomes, there are also different types of regression methods that are suited for each type. You likely have learned about linear and logistic regression in previous classes. We will review both in the following sections.</p>
<p>Throughout I will use <span class="math inline">\(Y\)</span> to denote the outcome variable and <span class="math inline">\(x_1,\ldots,x_p\)</span> to denote <span class="math inline">\(p\)</span> covariates. <span class="math inline">\(E[Y]\)</span> denotes the <strong>expected value</strong> of <span class="math inline">\(Y\)</span> and is another way of writing the <em>mean</em> of <span class="math inline">\(Y\)</span>. It describes the average value of the outcome we would see if we had data on a very large number of outcomes. <span class="math inline">\(E[Y]\)</span> is an example of a <strong>parameter</strong> as we talked about in Chapter @ref(chap_hypo_test). It is a true underlying value that describes a characteristic of the population.</p>
<p>It will also be helpful to know the term <strong>linear combination</strong>. If <span class="math inline">\(x_1,\ldots,x_p\)</span> are covariate values, then a linear combination of these covariates is written as:</p>
<p><span class="math display">\[ LC = a_1 x_1 + \cdots + a_p x_p \]</span></p>
<p>where <span class="math inline">\(a_1,\ldots,a_p\)</span> are numbers and the result <span class="math inline">\(LC\)</span> is a number as well.</p>
</div>
<div id="linear-regression" class="section level2">
<h2><span class="header-section-number">2.2</span> Linear regression</h2>
<p>In linear regression, we want to describe continuous measures as a function of covariates. To be concrete, let’s say that our outcome measure <span class="math inline">\(Y\)</span> is the concentration of HIV particles in the blood and that <span class="math inline">\(x_1,x_2,x_3\)</span> indicate clinical and demographic covariates that might reasonably affect viral particle concentration, say age in years, sex (1 for females, 0 for males), and antiretroviral (ART) drug dosage in milligrams (mg).</p>
<p>In linear regression, we model the expected value of <span class="math inline">\(Y\)</span> as a linear combination of covariates:</p>
<p><span class="math display">\[ E[Y] = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 \]</span></p>
<p><span class="math inline">\(\beta_0,\beta_1,\beta_2,\beta_3\)</span> are called <strong>regression coefficients</strong> and are simply numbers. <strong>Fitting</strong> a linear regression model is the computational process of estimating the numeric values of the <span class="math inline">\(\beta\)</span>’s (column 1 in the table below).</p>
<pre><code>##          term   estimate  std.error  statistic      p.value
## 1 (Intercept)  3.4904393 0.66590221  5.2416695 2.358704e-07
## 2         age  0.3906799 0.01659026 23.5487538 7.255804e-83
## 3         sex  0.1537585 0.36077712  0.4261869 6.701566e-01
## 4         ART -0.1161197 0.07827203 -1.4835399 1.385662e-01</code></pre>
<div id="interpreting-coefficients" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Interpreting coefficients</h3>
<p>The regression coefficients in front of the covariates (<span class="math inline">\(\beta_1,\beta_2,\beta_3\)</span>) have the nice interpretation of being the <em>expected change in outcome per 1 unit increase in the predictor, holding all other variables constant</em>. To see this, let’s look at age (<span class="math inline">\(x_1\)</span>). We will compare two people who are identical in terms of sex and ART dosage but who differ in age by 1.</p>
<p>Person 1: Age = <span class="math inline">\(a\)</span>, sex = <span class="math inline">\(s\)</span>, ART dosage = <span class="math inline">\(d\)</span> Person 2: Age = <span class="math inline">\(a+1\)</span>, sex = <span class="math inline">\(s\)</span>, ART dosage = <span class="math inline">\(d\)</span></p>
<p>We can write the expected HIV particle concentration for each of them:</p>
<p>Person 1: <span class="math inline">\(E[Y_1] = \beta_0 + \beta_1a + \beta_2s + \beta_3d\)</span> Person 2: <span class="math inline">\(E[Y_2] = \beta_0 + \beta_1(a+1) + \beta_2s + \beta_3d\)</span></p>
<p>The expected change in outcome comparing person 2 to person 1 is <span class="math inline">\(E[Y_2] - E[Y_1]\)</span>:</p>
<p><span class="math display">\[ E[Y_2] - E[Y_1] = \beta_1 \]</span></p>
<p>Thus, we see that <span class="math inline">\(\beta_1\)</span> is the expected change in HIV concentration per year increase in age, holding sex and ART dosage constant.</p>
<p>What about <span class="math inline">\(\beta_0\)</span>? <span class="math inline">\(\beta_0\)</span> is called the <strong>intercept</strong> and represents the expected outcome (mean HIV particle concentration) for a person who has age 0, is male, and has an ART dosage of 0. It is somewhat odd to imagine someone with age 0, so for this reason, predictor variables like age are often <strong>mean-centered</strong>.</p>
<p><span class="math display">\[ E[Y] = \beta_0 + \beta_1 (x_1 - \bar{x_1}) + \beta_2 x_2 + \beta_3 (x_3 - \bar{x_3}) \]</span></p>
<p>The numeric values and the interpretations of <span class="math inline">\(\beta_1,\beta_2,\beta_3\)</span> don’t change, but the numeric value and interpretation of <span class="math inline">\(\beta_0\)</span> will change. It is now interpreted as something more sensible: the expected outcome for someone of average age <span class="math inline">\(\bar{x_1}\)</span>, male, and of average ART dosage <span class="math inline">\(\bar{x_3}\)</span>.</p>
</div>
<div id="interaction" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Interaction</h3>
<p>The coefficients in the model we looked at above are all called <strong>main effects</strong>. They describe the effects of covariates holding constant the other covariates. Important to notice in this interpretation is that the effect of some factor is the <em>same across all individuals</em>.</p>
<p>Often times, we wish to understand if effects are <em>different across different groups</em>. This can be achieved by including interaction terms in a regression model. Most often researchers will include an interaction between a continuous variable and a categorical one or between two categorical variables. For example:</p>
<ul>
<li>How does the age effect differ across different socioeconomic categories?</li>
<li>How does the race effect differ across different countries?</li>
</ul>
</div>
</div>
<div id="logistic-regression" class="section level2">
<h2><span class="header-section-number">2.3</span> Logistic regression</h2>
<p>While linear regression is used to describe continuous measures as a function of covariates, logistic regression is used to describe the probability of a binary event as a function of covariates. For logistic regression, it is helpful to remember the definition of <strong>odds</strong>. The odds of an event is the ratio of the probability of the event happening to the the probability of the event not happening. If <span class="math inline">\(p\)</span> is the probability of the event happening, then the odds of the event can be written as:</p>
<p><span class="math display">\[ \hbox{odds} = \frac{p}{1-p} \]</span></p>
<p>In logistic regression, we model the expected log odds of a binary event as a linear combination of covariates:</p>
<p><span class="math display">\[ E[Y] = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 \]</span></p>
<p>We can go through the same process as with linear regression to obtain interpretations of coefficients in logistic regression. In linear regression, coefficients were interpreted as the expected change in outcome per unit change in covariate holding all other factors constant. In logistic regression, we replace “outcome” with “log odds of the binary event.” So in logistic regression, the coefficients give the difference in log odds of the event, more commonly expressed as the log odds ratio. For example, if the binary event were disease, the interpretation of an age coefficient would be</p>
<p><span class="math display">\[ \log\left( \frac{\hbox{odds of having disease at age a+1}}{\hbox{odds of having disease at age a}} \right) \]</span></p>
<p>In publications, these are almost always presented in exponentiated form:</p>
<p><span class="math display">\[ \frac{\hbox{odds of having disease at age a+1}}{\hbox{odds of having disease at age a}} \]</span></p>
</div>
<div id="generalized-linear-models" class="section level2">
<h2><span class="header-section-number">2.4</span> Generalized linear models</h2>
<p>With linear and logistic regression we have dealt with continous and binary outcomes respectively. What about categorical outcomes with more than two categories, which are common in surveys and medical situations where severity is an outcome? What about count data, which arise commonly in public health via incidence rates?</p>
<p>There is a class of models in statistics called <strong>generalized linear models</strong> that allows a variety of outcome variables to be used as the dependent variable - not just continuous and binary as we have seen with linear and logistic regression, but also count and categorical data with more than two outcomes.</p>
<p>Generalized linear models have the general form:</p>
<p><span class="math display">\[ f(E[Y]) = \beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p \]</span></p>
<p>In words, the left side <span class="math inline">\(f(E[Y])\)</span> just describes some function of the expected outcome. The right side is the familiar linear combination of covariates.</p>
<p>For linear regression, the function <span class="math inline">\(f\)</span> is the identity function <span class="math inline">\(f(x) = x\)</span> and <span class="math inline">\(E[Y]\)</span> indicates the expected/mean outcome which depends on the covariates.</p>
<p>For logistic regression, the function <span class="math inline">\(f\)</span> is the logit function:</p>
<p><span class="math display">\[ f(E[Y]) = \log\left( \frac{E[Y]}{1-E[Y]} \right) \]</span></p>
<p>In logistic regression, the outcome <span class="math inline">\(Y\)</span> is the binary 0/1 indicator of group and <span class="math inline">\(E[Y]\)</span> indicates the probability of being in group 1 (e.g. the probability of being a case in a case-control study). So in more familiar form, the above expression is the log odds of being in group 1:</p>
<p><span class="math display">\[ f(p) = \log\left( \frac{p}{1-p} \right) \]</span></p>
<p>Similar ideas apply for when <span class="math inline">\(Y\)</span> is a different type of outcome variable (e.g. general categorical, count). The main idea with generalized linear models is that it is possible to perform regression for a wide variety of outcome variables.</p>
</div>
<div id="model-selection" class="section level2">
<h2><span class="header-section-number">2.5</span> Model selection</h2>
<p>What variables should be included in a regression model? It is tempting to just include them all and let the computer do the work, but we need to be careful. Say we have 100 subjects and 50 predictors. There is no way we have enough information with only 100 subjects to get reliable information on all of those predictors. This is an idea called the curse of dimentionality: the more variables we have for a fixed size dataset the less information we have to learn about each variable. Model selection techniques are used to identify the most relevant variables in explaining an outcome. If we are able to identify the most important variables, we can use this subset for regression. We will discuss techniques for this in class.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chap-hypo-test.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chap-causal-background.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["stat_thinking.pdf"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
